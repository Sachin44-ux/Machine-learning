# README: Breast Cancer Diagnosis with Naïve Bayes Classifier

## Overview
This project implements a **Naïve Bayes classifier** to predict breast cancer diagnosis (malignant or benign) using the **Breast Cancer Wisconsin Dataset**. The objective is to classify tumors based on medical features, evaluating the model with metrics such as accuracy, precision, and recall.

## Dataset
- **Source**: [Breast Cancer Wisconsin Dataset](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data) (available on Kaggle)
- **Description**: Contains 569 samples with 32 columns:
  - `id`: Unique identifier
  - `diagnosis`: Target variable (`M` for malignant, `B` for benign)
  - 30 numerical features describing tumor characteristics (e.g., `radius_mean`, `texture_mean`, `perimeter_mean`, `area_mean`, etc.)
- **File**: `breast-cancer.csv`
- **Size**: 569 rows, no missing values

## Prerequisites
To run the code, install the following Python libraries:
- `pandas`
- `scikit-learn`

Install them using:
```bash
pip install pandas scikit-learn
```

## Project Structure
- **Notebook**: `breast-cancer.ipynb` (contains code for data loading, analysis, preprocessing, model training, and evaluation)
- **Dataset Path**: Expected at `/kaggle/input/breast-cancer-dataset/breast-cancer.csv`. Update the path in the code if running locally.
- **Environment**: Python 3.10.14 (tested on Kaggle, compatible with Jupyter Notebook, Google Colab, or similar)

## Workflow
The code follows these steps:
1. **Library Imports**:
   - `pandas` for data manipulation
   - `sklearn` modules for:
     - Data splitting (`train_test_split`)
     - Model implementation (`GaussianNB`)
     - Preprocessing (`StandardScaler`)
     - Evaluation (`accuracy_score`, `precision_score`, `recall_score`, `confusion_matrix`)

2. **Data Analysis**:
   - Loads the dataset using `pd.read_csv()`.
   - Displays the first 5 rows to inspect the structure.
   - Checks for missing values (none found).
   - Drops rows with missing values (precautionary, not needed here).
   - Provides dataset info and summary statistics (`df.info()`, `df.describe()`).

3. **Data Preprocessing**:
   - Maps `diagnosis` to binary values: `M` (malignant) → 1, `B` (benign) → 0.
   - Separates features (`X`: all columns except `diagnosis`) and target (`y`: `diagnosis`).
   - Scales features using `StandardScaler` to normalize their ranges.
   - Splits data into 80% training and 20% testing sets (`test_size=0.2`, `random_state=42`).

4. **Model Implementation**:
   - Instantiates a `GaussianNB` classifier, suitable for continuous features.
   - Trains the model on the scaled training data.

5. **Evaluation**:
   - Predicts on the test set.
   - Computes:
     - **Accuracy**: Proportion of correct predictions
     - **Precision**: Macro-averaged positive predictive value (equal weight to both classes)
     - **Recall**: Macro-averaged true positive rate
   - Outputs results as percentages.

## Results
The model achieves the following performance on the test set:
- **Accuracy**: 96.49%
- **Precision**: 96.73%
- **Recall**: 95.81%

These metrics indicate strong performance, with high accuracy and balanced precision/recall for both classes (benign and malignant).

## How to Run
1. **Setup**:
   - Place the dataset in the specified path or update the file path in the code.
   - Install dependencies (see Prerequisites).

2. **Execution**:
   - Open `breast-cancer.ipynb` in a Jupyter-compatible environment (e.g., Jupyter Notebook, Kaggle, Google Colab).
   - Run all cells sequentially.

   Command to start Jupyter Notebook:
   ```bash
   jupyter notebook breast-cancer.ipynb
   ```

3. **Output**:
   - The notebook displays:
     - First 5 rows of the dataset
     - Missing value check (none found)
     - Dataset info and summary statistics
     - Model performance metrics (accuracy, precision, recall)

## Notes
- **Data Quality**: The dataset is clean with no missing values, simplifying preprocessing.
- **Class Balance**: The dataset is moderately balanced (63% benign, 37% malignant), so no resampling was needed.
- **Model Choice**: `GaussianNB` assumes features follow a Gaussian distribution, which suits the continuous features here.
- **Performance**: The high accuracy suggests the model is effective, but results may vary slightly with different random splits.

## Limitations
- No hyperparameter tuning or cross-validation is performed, which could further optimize performance.
- Assumes Gaussian distribution for features, which may not perfectly fit all features.
- The `id` column is included in features, which may add noise (consider dropping it in future iterations).

## Future Improvements
- Drop the `id` column, as it’s irrelevant to predictions.
- Perform feature selection to identify the most predictive features.
- Use cross-validation to ensure robust performance.
- Compare with other classifiers (e.g., Logistic Regression, Random Forest, SVM).
- Visualize results (e.g., confusion matrix, ROC curve) for deeper insights.

## License
This project uses a publicly available dataset under its respective license. Ensure compliance when using or redistributing. The code is shared for educational purposes.

## Acknowledgments
- **Dataset**: Provided by the University of Wisconsin, hosted on Kaggle.
- **Tools**: Built with `pandas` and `scikit-learn`.
- **Environment**: Tested on Kaggle’s Python 3.10.14 kernel.

For issues or suggestions, contact the project author or open an issue/pull request on the repository (if applicable).
